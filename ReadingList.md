# Reading List
in lieu of EndNote, a list of potentially interesting items, organized by topic, and with notes

### Reinforcement learning
* [An introduction to Deep Reinforcement Learning](https://arxiv.org/pdf/1811.12560.pdf): a mini textbook of sorts
* [Experience replay for continual learning](https://arxiv.org/pdf/1811.11682.pdf): memory 'replay' buffers for reinforcement learning to address the problem of 'catestrophic forgetting' when switching tasks. Perhaps inspired by [neuronal (hippocampal) replay](https://www.ncbi.nlm.nih.gov/pubmed/8036517)?

### Natural language processing
* [Efficient vector representation for documents through corruption](https://arxiv.org/abs/1707.02377): aka Document Vector through Corruption (Doc2VecC), a spin on word embedding techniques (e.g. Word2Vec) whereby you randomly remove a *significant portion* of words in a document and then compute word embeddings on what's left. A computationally more tractable way of computing word embeddings while controlling for commonly occurring words.

### Odds and ends from notable Big Companies
* Amazon
  * [Hospital mortality prediction](https://arxiv.org/pdf/1811.12276.pdf)
  
